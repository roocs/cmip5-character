Sender: LSF System <lsfadmin@host422.jc.rl.ac.uk>
Subject: Job 9843054: </home/users/esmith88/roocs/character_scanner/scan.py -m MPI-M/MPI-ESM-MR -exp historical -e r1i1p1 -v rh> in cluster <lotus> Done

Job </home/users/esmith88/roocs/character_scanner/scan.py -m MPI-M/MPI-ESM-MR -exp historical -e r1i1p1 -v rh> was submitted from host <jasmin-sci2-panfs.ceda.ac.uk> by user <esmith88> in cluster <lotus>.
Job was executed on host(s) <host422.jc.rl.ac.uk>, in queue <short-serial>, as user <esmith88> in cluster <lotus>.
</home/users/esmith88> was used as the home directory.
</home/users/esmith88/roocs/character_scanner> was used as the working directory.
Started at Results reported on 
Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/users/esmith88/roocs/character_scanner/scan.py -m MPI-M/MPI-ESM-MR -exp historical -e r1i1p1 -v rh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.02 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   10 sec.
    Turnaround time :                            9 sec.

The output (if any) follows:

Completed job. Failure count = 1. Percentage failed = 100.0%


PS:

Read file </home/users/esmith88/roocs/character_scanner/ALL_OUTPUTS/cmip5/output1/MPI-M/MPI-ESM-MR/historical/LOTUS_outputs/r1i1p1.err> for stderr output of this job.

